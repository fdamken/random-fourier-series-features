The lack of a sense for uncertainty of \acp{NN} lead to an uptick in usage of \acp{GP} in control due to their outstanding uncertainty quantification.
A major drawback of using \acp{GP} is that their performance highly depends on the choice of the kernel.
To tackle this problem, methods for (deep) kernel learning (\acsu{DKL}) have been proposed throughout the years.
However, a second major problem remains: (exact) inference in \acp{GP} is intractable for large data sets.
Numerous methods have been proposed to remedy this problem such as inducing points and \acp{RFF}.
We extend \acp{RFF} to \acp{RFSF} by incorporating ideas from Fourier (series) analysis.
This combines the predictive power of \acp{NN} with the advantages of \acp{GP} and fights intractable inference.
However, we found that the advantage was minimal and, in some cases, non-existent.
