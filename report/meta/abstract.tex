Neural networks (\acspu{NN}) are powerful prediction models used in various domains such as robotics control.
However, they lack a principled approach for uncertainty quantification.
While research has been conducted towards \acp{BNN}, \acp{GP} remain the go-to approach for reliable uncertainty estimation, capturing both aleatoric and epistemic uncertainty.
This weakness is due to the intractability of inference on \acp{BNN} and a lack of principled and scalable approximate inference methods.
However, the success of a \ac{GP} highly depends on the kernel \emph{design}, i.e., the kernel is not learned from data.
We propose \acp{RFSF}, an extension of the well-known \acp{RFF} to bridge the gap between the data-driven features of \acp{NN} and the powerful inductive biases and practical inference of \acp{GP}.
