\documentclass[
	USenglish,
	aspectratio=43,
	color={accentcolor=1c},
	logo=true,
	colorframetitle=true,
	hyperref={pdfpagelabels=true},
]{tudabeamer}

% Core Packages.
\usepackage[USenglish]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
% Math Packages.
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{bbm}
\usepackage{physics}
\usepackage{siunitx}
% Other Packages.
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{eqparbox}
\usepackage{datetime}
\usepackage{layouts}
\usepackage{multimedia}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{pgfplots}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{tikzscale}
% TikZ Libraries.
\usetikzlibrary{calc, arrows.meta, positioning}

% Style Definitions.
\mode<presentation>
\MakeOuterQuote{"}
\captionsetup{labelformat=empty}
\tikzset{> = { Latex[length = 2mm] }}
\mathtoolsset{showonlyrefs, showmanualtags}
\colorlet{pastelGreen}{TUDa-3c}
\colorlet{pastelBlue}{TUDa-2b}
\colorlet{pastelOrange}{TUDa-7c}
\newcommand{\ifincludelegend}[1]{}
\input{preamble/math-macros}
\AtBeginSection{
	\begin{frame}{\insertsectionhead \\ {\small Outline}}
		\tableofcontents[currentsection]
	\end{frame}
}
\AtBeginSubsection{
	\begin{frame}{\insertsubsectionhead \\ {\small Outline}}
		\tableofcontents[currentsection, currentsubsection]
	\end{frame}
}

\newcommand{\hypOne}{
	\begin{block}{Central Hypothesis}
		Random Fourier series features outperform random Fourier features.
	\end{block}
}
%\newcommand{\hypTwo}{
%	\begin{block}{Hypothesis 2}
%		How do different amplitude initializations affect the performance?
%	\end{block}
%}

\newcommand{\acs}[1]{#1}
\newcommand{\acsp}[1]{#1s}
\input{content/results}

% Document Information.
\title{Random Fourier Series Features}
\subtitle{Defense \enquote{Expert Lab on Robot Learning}}
\author{Fabian Damken}
\institute{Intelligent Autonomous Systems}
\department{Department of Computer Science}
\date{\formatdate{20}{05}{2022}}

\logo*{\includegraphics{graphics/ias-logo}}
\titlegraphic*{\includegraphics[height=6.4cm]{graphics/generated/title2}}

\begin{document}
	\maketitle

	\section{Motivation}
		\begin{frame}{Deep Learning and Neural Networks}
			\begin{itemize}
				\item<+-> (Deep) neural networks dominate AI
					\begin{itemize}
						\item<+-> extremely expressive
						\item<.-> great predictive power
						\item<+-> lack uncertainty estimation
					\end{itemize}
				\item<+-> Lead to the development of \emph{Bayesian} neural networks
					\begin{itemize}
						\item<+-> intractable exact inference
						\item<.-> complicated training
%						\item<.-> unreliable uncertainty quantification
						\item<.-> \dots
					\end{itemize}
			\end{itemize}
		\end{frame}

		\begin{frame}{Gaussian Processes (GPs)}
			\begin{itemize}
				\item<+-> GPs are still the go-to model for reliable uncertainty quantification
				\item<+-> but performance highly depends on the kernel choice\dots
					\begin{itemize}
						\item tackled by kernel learning
					\end{itemize}
				\item<+-> exact inference complexity is cubic w.r.t. number of data points
					\begin{itemize}
						\item prohibits online use of GPs
					\end{itemize}
			\end{itemize}
		\end{frame}
	% end

	\section{Methodology}
		\begin{frame}{Random Fourier Features}
			\begin{equation}
				\vec{z}_{\vec{\omega}}(\vec{x}) =
					\begin{bmatrix}
						\cos(\ip{\vec{\omega}}{\vec{x}}) \\
						\sin(\ip{\vec{\omega}}{\vec{x}})
					\end{bmatrix}
			\end{equation}
			\begin{itemize}
				\item<+-> resort to "classical" Bayesian regression
				\item<.-> explicit posterior over the weights
				\item<+-> approximate every stationary kernel \( k(\cdot) \):
			\end{itemize}
			\onslide<.->{
				\begin{gather}
					k(\vec{x} - \vec{y})
						= \E_{\vec{\omega} \sim p(\cdot)}\bigl[ \ip{\vec{z}_{\vec{\omega}}(\vec{x})}{\vec{z}_{\vec{\omega}}(\vec{y})} \bigr]
						\approx \frac{1}{N} \sum_{i = 1}^{N} \ip{\vec{z}_{\vec{\omega}_i}(\vec{x})}{\vec{z}_{\vec{\omega}_i}(\vec{y})},\quad
						\vec{\omega}_i \sim p(\cdot)
				\end{gather}
			}
		\end{frame}

		\begin{frame}{Random Fourier Features}{Approximating the Squared Exponential}
			\onslide<+->{For the SE kernel: tractable Fourier transform}
			\begin{gather}
				\onslide<+->{
					\begin{aligned}
						k_\mathrm{SE}(\vec{x} - \vec{y}) &= \exp\bigl\{ \flatfrac{-\ip{\vec{x} - \vec{y}}{\vec{x} - \vec{y}}}{\,2} \bigr\} \\
						p(\vec{\omega}) = \bigl(\mathcal{F} k_\mathrm{SE}\bigr)(\vec{\omega}) &= \mathcal{N}(\vec{\omega} \given \vec{0}, \mat{I})
					\end{aligned} \\\\
				}
				\onslide<+->{
					\begin{aligned}
						\E\bigl[ \ip{\vec{z}_{\vec{\omega}}(\vec{x})}{\vec{z}_{\vec{\omega}}(\vec{y})} \bigr]
							&= \E\Biggl[
								\ip{
									\begin{bmatrix}
										\cos(\ip{\vec{\omega}}{\vec{x}}) \\
										\sin(\ip{\vec{\omega}}{\vec{x}})
									\end{bmatrix}
								}{
									\begin{bmatrix}
										\cos(\ip{\vec{\omega}}{\vec{y}}) \\
										\sin(\ip{\vec{\omega}}{\vec{y}})
									\end{bmatrix}}
								\Biggr] \\
							&= \E\bigl[ \cos(\ip{\vec{\omega}}{\vec{x}}) \cos(\ip{\vec{\omega}}{\vec{y}}) + \sin(\ip{\vec{\omega}}{\vec{x}}) \sin(\ip{\vec{\omega}}{\vec{y}}) \bigr] \\
							&= \E\bigl[ \cos(\ip{\vec{\omega}}{\vec{x} - \vec{y}}) \bigr]
							 = \Re\bigl( \E\bigl[ \exp\{ i \ip{\vec{\omega}}{\vec{x} - \vec{y}} \} \bigr] \bigr) \\
							&= \Re\bigl( \bigl(\mathcal{F}^{-1} p\bigr)(\vec{x} - \vec{y}) \bigr)
							 = \Re\bigl( k_\mathrm{SE}(\vec{x} - \vec{y}) \bigr)
							 = k_\mathrm{SE}(\vec{x} - \vec{y})
					\end{aligned}
				}
			\end{gather}
			\begin{itemize}
				\item<+-> SE kernel is extremely smooth (Stein, 1999)
			\end{itemize}
		\end{frame}

		\begin{frame}{Random Fourier \emph{Series} Features}
			We extend random Fourier features:
			\begin{equation}
				\begin{aligned}
					\vec{z}_{\vec{\omega}}(\vec{x}) &=
						\begin{bmatrix}
							\cos(\ip{\vec{\omega}}{\vec{x}}) \\
							\sin(\ip{\vec{\omega}}{\vec{x}})
						\end{bmatrix}
				\end{aligned}
				\quad\longrightarrow\qquad
				\begin{aligned}
					\vec{z}_{\vec{\omega}}(\vec{x}) &= \sum_{k = 1}^{K} \vec{z}_{\vec{\omega}}^{(k)}(\vec{x}), \\
					\vec{z}_{\vec{\omega}}^{(k)}(\vec{x}) &=
						\begin{bmatrix}
							a_k \cos(\pi \tilde{T}^{-1} k \mel{\vec{\omega}}{\bm{\Lambda}^{-1}}{\vec{x}}) \\
							b_k \sin(\pi \tilde{T}^{-1} k \mel{\vec{\omega}}{\bm{\Lambda}^{-1}}{\vec{x}})
						\end{bmatrix}
				\end{aligned}
			\end{equation}
			\begin{itemize}
				\item<+-> similar to the sine-cosine formulation of Fourier series
			\end{itemize}
		\end{frame}

		\begin{frame}{Fourier Series}{Sine-Cosine Formulation}
%					\\
%					a_k = \frac{1}{\tilde{T}} \int_{x_0}^{x_0 + 2 \tilde{T}}\! f(x) \cos(\omega k x) \dd{x} \qquad
%					b_k = \frac{1}{\tilde{T}} \int_{x_0}^{x_0 + 2 \tilde{T}}\! f(x) \sin(\omega k x) \dd{x}
			\begin{equation}
				\hat{f}_K(x) = \frac{a_0}{2} + \sum_{k = 1}^{K} a_k \cos(\pi \tilde{T}^{-1} k x) + b_k \sin(\pi \tilde{T}^{-1} k x)
			\end{equation}
			\begin{center}
				\includegraphics[width=0.55\linewidth]{graphics/generated/relu.pdf}
			\end{center}
		\end{frame}
	% end

	\section{Evaluation}
		\begin{frame}{Hypothesis}
			\hypOne
		\end{frame}

		\begin{frame}{Evaluation}
			\begin{itemize}
				\item<+-> Datasets:
					\begin{itemize}
						\item Synthetic Data (Cosine, Heaviside, Heavi-Cosine, Gap-Cosine)
						\item UCI (Boston, Concrete, Power, Yacht, Energy, Kin8nm, Naval, Protein, Wine)
						\item Cartpole
					\end{itemize}
				\item<+-> Different RFSF Initializations:
					\begin{itemize}
						\item Random
						\item ReLU
						\item Single Harmonic (SH)
					\end{itemize}
			\end{itemize}
		\end{frame}

		\begin{frame}{How the Kernel Learns}
			\begin{columns}
				\begin{column}{0.5\linewidth}
					\centering
					\movie[loop]{\includegraphics[width=\linewidth]{graphics/kernel-animation/rfsf/prior-covariance.png}}{graphics/kernel-animation/rfsf/prior-covariance.webm}
					RFSF on Gap-Cosine
				\end{column}
				\begin{column}{0.5\linewidth}
					\centering
					\movie[loop]{\includegraphics[width=\linewidth]{graphics/kernel-animation/rff/prior-covariance.png}}{graphics/kernel-animation/rff/prior-covariance.webm}
					RFFs on Gap-Cosine
				\end{column}
			\end{columns}
		\end{frame}

		\begin{frame}{Results on the Synthetic Data}
			\begin{center}
				\begin{tabular}{c|cc}
					& RFSFs & RFFs \\ \midrule
					\rotatebox{90}{\parbox{0.22\linewidth}{\centering Gap-Cosine}}
					& \includegraphics[width=0.4\linewidth, height=0.22\linewidth]{graphics/generated/gp-gapcosine-rfsf.tikz}
					& \includegraphics[width=0.4\linewidth, height=0.22\linewidth]{graphics/generated/gp-gapcosine-rff.tikz}
					\\
					\rotatebox{90}{\parbox{0.22\linewidth}{\centering Heavi-Cosine}}
					& \includegraphics[width=0.4\linewidth, height=0.22\linewidth]{graphics/generated/gp-heavicosine-rfsf.tikz}
					& \includegraphics[width=0.4\linewidth, height=0.22\linewidth]{graphics/generated/gp-heavicosine-rff.tikz}
				\end{tabular}
			\end{center}
		\end{frame}

		\begingroup
		\let\scriptsize\relax
		\begin{frame}{Quantified Results}{Synthetic Data Sets and Cartpole}
			\begin{center}
				\tiny
				\begin{tabular}{c|cc|ccccc}
					\toprule
					& & & \multicolumn{5}{c}{\textbf{Data Set}} \\[1pt]
					& \multicolumn{2}{c|}{\textbf{Model}}         & Cosine                 & Heaviside              & Heavi-Cosine            & Gap-Cosine             & Cartpole                          \\
					\midrule \multirow{5}{*}{\rotatebox{90}{\textbf{Log-Lik.}}}
					& \multirow[t]{3}{*}{\textit{RFSF}} & \textit{Random}     & \textit{\textbf{\texttt{2.43}}} & \textit{\texttt{0.11}}          & \textit{\texttt{-1.66}}          & \textit{\texttt{1.27}}          & \textit{\texttt{~-9.88\,Â±\,1.86}}          \\
					&                                & \textit{\acs{ReLU}} & \textit{\texttt{2.34}}          & \textit{\textbf{\texttt{0.80}}} & \textit{\texttt{-0.90}}          & \textit{\texttt{1.50}}          & \textit{\texttt{-12.30\,Â±\,2.31}}          \\
					&                                & \textit{\acs{SH}}   & \textit{\texttt{2.37}}          & \textit{\textbf{\texttt{0.21}}} & \textit{\texttt{-1.23}}          & \textit{\texttt{1.52}}          & \textit{\texttt{~-9.73\,Â±\,2.10}}          \\
					& \multirow[t]{2}{*}{\acs{GP}}   & \acs{SE}   & \textbf{\texttt{2.44}} & \texttt{0.73}          & \textbf{\texttt{~0.77}} & \textbf{\texttt{2.58}} & \textbf{\texttt{~-3.21\,Â±\,1.64}} \\
					&                                & \acs{RFF}  & \textbf{\texttt{2.44}} & \texttt{0.73}          & \textbf{\texttt{~0.78}} & \textbf{\texttt{2.59}} & \texttt{~-7.38\,Â±\,1.94}          \\
					\bottomrule
				\end{tabular}
			\end{center}
		\end{frame}

		\begin{frame}{Quantified Results}{UCI Data Sets}
			\begin{center}
				\tiny
				\begin{tabular}{c|cc|cccc}
					\toprule
					& & & \multicolumn{4}{c}{\textbf{Data Set}} \\[1pt]
					& \multicolumn{2}{c|}{\textbf{Model}}                               & Boston                           & Concrete                         & Power                            & Yacht                            \\
					\midrule \multirow{11}{*}{\rotatebox{90}{\textbf{Log-Lik.}}}
					& \multirow[t]{3}{*}{\textit{RFSF}}             & \textit{Random}           & \textit{\texttt{-2.40\,Â±\,0.05}}          & \textit{\textbf{\texttt{-2.94\,Â±\,0.05}}} & \textit{\texttt{-2.78\,Â±\,0.01}}          & \textit{\texttt{-0.80\,Â±\,0.02}}          \\
					&                                            & \textit{\acs{ReLU}}       & \textit{\texttt{-2.39\,Â±\,0.05}}          & \textit{\textbf{\texttt{-2.93\,Â±\,0.04}}} & \textit{\texttt{-2.80\,Â±\,0.01}}          & \textit{\texttt{-0.86\,Â±\,0.02}}          \\
					&                                            & \textit{\acs{SH}}         & \textit{\texttt{-2.44\,Â±\,0.06}}          & \textit{\textbf{\texttt{-2.94\,Â±\,0.05}}} & \textit{\texttt{-2.78\,Â±\,0.01}}          & \textit{\texttt{-0.83\,Â±\,0.02}}          \\
					& \multirow[t]{2}{*}{\acs{GP}}               & \acs{SE}         & \textbf{\texttt{-2.38\,Â±\,0.05}} & \textbf{\texttt{-2.98\,Â±\,0.06}} & \texttt{-2.82\,Â±\,0.01}          & \texttt{-0.80\,Â±\,0.02}          \\
					&                                            & \acs{RFF}        & \texttt{-2.40\,Â±\,0.06}          & \textbf{\texttt{-3.01\,Â±\,0.05}} & \texttt{-2.84\,Â±\,0.01}          & \texttt{-0.80\,Â±\,0.02}          \\
					& \multirow[t]{2}{*}{\acs{GBLL}}\footnotemark[1] & Leaky \acs{ReLU} & \texttt{-2.90\,Â±\,0.05}          & \texttt{-3.09\,Â±\,0.03}          & \texttt{-2.77\,Â±\,0.01}          & \texttt{-1.67\,Â±\,0.11}          \\
					&                                            & Tanh             & \texttt{-3.06\,Â±\,0.03}          & \texttt{-3.21\,Â±\,0.03}          & \texttt{-2.83\,Â±\,0.01}          & \texttt{-0.70\,Â±\,0.10}          \\
					& \multirow[t]{2}{*}{Ensemble}\footnotemark[1]   & Leaky \acs{ReLU} & \texttt{-2.48\,Â±\,0.09}          & \textbf{\texttt{-3.04\,Â±\,0.08}} & \textbf{\texttt{-2.70\,Â±\,0.01}} & \texttt{-0.35\,Â±\,0.07}          \\
					&                                            & Tanh             & \texttt{-2.48\,Â±\,0.08}          & \textbf{\texttt{-3.03\,Â±\,0.07}} & \textbf{\texttt{-2.72\,Â±\,0.01}} & \textbf{\texttt{-0.03\,Â±\,0.05}} \\
					& \multirow[t]{2}{*}{\acs{MAP}}\footnotemark[1]  & Leaky \acs{ReLU} & \texttt{-2.60\,Â±\,0.07}          & \texttt{-3.04\,Â±\,0.04}          & \texttt{-2.77\,Â±\,0.01}          & \texttt{-5.14\,Â±\,1.62}          \\
					&                                            & Tanh             & \texttt{-2.59\,Â±\,0.06}          & \texttt{-3.11\,Â±\,0.04}          & \texttt{-2.76\,Â±\,0.01}          & \texttt{-1.77\,Â±\,0.53}          \\
					\bottomrule
				\end{tabular}
				\footnotetext[1]{Results taken from Watson et al. (2021), "Latent Derivative Bayesian Last Layer Networks."}
			\end{center}
		\end{frame}
		\endgroup
	% end

	\section{Conclusion}
		\begin{frame}{Conclusion}
			\onslide<+->{\hypOne}

			\begin{itemize}
				\item<+-> we compared to RFFs, SE, and BNN methods
				\item<+-> advantage of RFSFs is not consistent
				\item<.-> no performance gain
				\item<.-> also true for the SH initialization
			\end{itemize}
		\end{frame}

		\begin{frame}{Future Work}
			\begin{itemize}
				\item theoretical analysis what RFSFs approximate
				\item better understanding of the half-period initialization
			\end{itemize}
		\end{frame}
	% end


	\appendix
	\section{Methodology}
		\begin{frame}{Hyper-Parameter Optimization}
			\begin{columns}
				\begin{column}{0.5\linewidth}
					\begin{itemize}
						\item Hyper-Parameters
							\begin{itemize}
								\item \eqmakebox[hyperParams][l]{\(\vec{a}_{1:K}\)} (sine coefficients)
								\item \eqmakebox[hyperParams][l]{\(\vec{b}_{1:K}\)} (cosine coefficients)
								\item \eqmakebox[hyperParams][l]{\(\bm{\Lambda}\)}  (length-scales)
								\item \eqmakebox[hyperParams][l]{\(\tilde{T}\)}     (half-period)
								\item \eqmakebox[hyperParams][l]{\(\sigma_n^2\)}    (aleatoric noise variance)
							\end{itemize}
						\item maximization of the marginal log-likelihood
						\item using the empirical Bayes approximation
					\end{itemize}
				\end{column}
				\begin{column}{0.5\linewidth}
					\begin{align}
						\vec{z}_{\vec{\omega}}(\vec{x}) &= \sum_{k = 1}^{K} \vec{z}_{\vec{\omega}}^{(k)}(\vec{x}), \\
						\vec{z}_{\vec{\omega}}^{(k)}(\vec{x}) &=
							\begin{bmatrix}
								a_k \cos(\pi \tilde{T}^{-1} k \mel{\vec{\omega}}{\bm{\Lambda}^{-1}}{\vec{x}}) \\
								b_k \sin(\pi \tilde{T}^{-1} k \mel{\vec{\omega}}{\bm{\Lambda}^{-1}}{\vec{x}})
							\end{bmatrix}
					\end{align}
				\end{column}
			\end{columns}
		\end{frame}
	% end

	\section{Evaluation}
		\begin{frame}{Quantified Results}{UCI Data Sets; Cont.}
			\begin{center}
				\tiny
				\begin{tabular}{c|cc|ccccc}
					\toprule
					& & & \multicolumn{5}{c}{\textbf{Data Set}} \\[1pt]
					& \multicolumn{2}{c|}{\textbf{Model}}             & Energy                           & Kin8nm                           & Naval                                 & Protein                              & Wine                             \\
					\midrule \multirow{5}{*}{\rotatebox{90}{\textbf{Log-Lik.}}}
					& \multirow[t]{3}{*}{\textit{\acs{RFSF}}} & \textit{Random}         & \textit{\textbf{\texttt{-0.70\,Â±\,0.02}}} & \textit{\texttt{~0.68\,Â±\,0.05}}          & \textit{\texttt{~~-78.19\,Â±\,~69.72}}          & \textit{\texttt{~~-2.94\,Â±\,~~0.03}}          & \textit{\texttt{-0.11\,Â±\,0.07}}          \\
					&                                & \textit{\acs{ReLU}}     & \textit{\texttt{-0.74\,Â±\,0.02}}          & \textit{\textbf{\texttt{~0.97\,Â±\,0.03}}} & \textit{\texttt{~-172.57\,Â±\,104.83}}          & \textit{\texttt{-629.05\,Â±\,384.60}}          & \textit{\texttt{-0.11\,Â±\,0.06}}          \\
					&                                & \textit{\acs{SH}}       & \textit{\texttt{-0.74\,Â±\,0.02}}          & \textit{\texttt{~0.52\,Â±\,0.07}}          & \textit{\texttt{~~-62.69\,Â±\,~55.40}}          & \textit{\texttt{~~-2.96\,Â±\,~~0.03}}          & \textit{\textbf{\texttt{ 0.01\,Â±\,0.06}}} \\
					& \multirow[t]{2}{*}{\acs{GP}}   & \acs{SE}       & \textbf{\texttt{-0.68\,Â±\,0.02}} & \texttt{-0.22\,Â±\,0.24}          & \textbf{\texttt{~~~~6.91\,Â±\,~~0.15}} & \textbf{\texttt{~~-2.89\,Â±\,~~0.00}} & \texttt{-0.84\,Â±\,0.05}          \\
					&                                & \acs{RFF}      & \textbf{\texttt{-0.69\,Â±\,0.02}} & \texttt{~0.75\,Â±\,0.04}          & \texttt{-1941.56\,Â±\,248.64}          & \texttt{~~-2.90\,Â±\,~~0.00}          & \texttt{-0.89\,Â±\,0.04}          \\
					\bottomrule
				\end{tabular}
			\end{center}
		\end{frame}
	% end
\end{document}
